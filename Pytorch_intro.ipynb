{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from __future__ import print_function\nimport torch","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Create 5x3 matrix\nx = torch.empty(5,3)\nx","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"tensor([[1.7150e-04, 3.0652e-41, 1.7410e-04],\n        [3.0652e-41, 1.7410e-04, 3.0652e-41],\n        [1.7410e-04, 3.0652e-41, 1.7150e-04],\n        [3.0652e-41, 1.7150e-04, 3.0652e-41],\n        [1.7150e-04, 3.0652e-41, 2.4770e-05]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create matrix with random initialize values\n# Values between 0-1\nx = torch.rand(5,3)\nx","execution_count":47,"outputs":[{"output_type":"execute_result","execution_count":47,"data":{"text/plain":"tensor([[0.6244, 0.2277, 0.4348],\n        [0.8979, 0.5292, 0.2152],\n        [0.1704, 0.2907, 0.9612],\n        [0.1775, 0.4978, 0.6001],\n        [0.0123, 0.7358, 0.3189]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create matrix with zero values\nx = torch.zeros(5,3, dtype=torch.int64)\nx","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"tensor([[0, 0, 0],\n        [0, 0, 0],\n        [0, 0, 0],\n        [0, 0, 0],\n        [0, 0, 0]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Construct tensor directly from data\nx = torch.tensor([5.5, 3])\nx","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"tensor([5.5000, 3.0000])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Overwrite previous x (above) with matrix of ones\nx = x.new_ones(5,3, dtype=torch.double)\nx","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"tensor([[1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.]], dtype=torch.float64)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Overwrites dtype\n# Random values\n# Matrix same size\nx = torch.randn_like(x, dtype=torch.float)\nx","execution_count":48,"outputs":[{"output_type":"execute_result","execution_count":48,"data":{"text/plain":"tensor([[-0.1309, -0.2005, -0.1495],\n        [ 0.0148,  0.5327,  0.3438],\n        [ 0.3951, -2.4601,  0.1134],\n        [-0.0042, -0.3959, -1.5248],\n        [ 0.4305, -0.8861, -1.6002]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get size\n# torch.Size is tuple\nprint(x.size())","execution_count":49,"outputs":[{"output_type":"stream","text":"torch.Size([5, 3])\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Operations"},{"metadata":{},"cell_type":"markdown","source":"## Addition"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding matrix\ny = torch.rand(5,3)\ny","execution_count":50,"outputs":[{"output_type":"execute_result","execution_count":50,"data":{"text/plain":"tensor([[0.2570, 0.2049, 0.0048],\n        [0.9180, 0.4589, 0.5666],\n        [0.6581, 0.1635, 0.5325],\n        [0.5456, 0.1701, 0.8847],\n        [0.9443, 0.4091, 0.2041]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x+y)","execution_count":51,"outputs":[{"output_type":"stream","text":"tensor([[ 0.1261,  0.0045, -0.1446],\n        [ 0.9328,  0.9916,  0.9105],\n        [ 1.0532, -2.2966,  0.6459],\n        [ 0.5413, -0.2259, -0.6401],\n        [ 1.3748, -0.4770, -1.3960]])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Addition 2nd way\nprint(torch.add(x,y))","execution_count":52,"outputs":[{"output_type":"stream","text":"tensor([[ 0.1261,  0.0045, -0.1446],\n        [ 0.9328,  0.9916,  0.9105],\n        [ 1.0532, -2.2966,  0.6459],\n        [ 0.5413, -0.2259, -0.6401],\n        [ 1.3748, -0.4770, -1.3960]])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Addition: provide output tensor as augument\nresult = torch.empty(5,3) # tensor must be same size as additions of tensors\ntorch.add(x,y, out=result)\nprint(result)","execution_count":54,"outputs":[{"output_type":"stream","text":"tensor([[ 0.1261,  0.0045, -0.1446],\n        [ 0.9328,  0.9916,  0.9105],\n        [ 1.0532, -2.2966,  0.6459],\n        [ 0.5413, -0.2259, -0.6401],\n        [ 1.3748, -0.4770, -1.3960]])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add x to y\ny.add_(x)\nprint(y)","execution_count":21,"outputs":[{"output_type":"stream","text":"tensor([[ 0.6183, -1.0658,  1.2523],\n        [ 0.5790,  1.3310, -2.4750],\n        [ 1.3688,  2.8949,  1.4571],\n        [ 1.2889,  0.9244, -0.9494],\n        [ 0.4999, -0.9303,  1.3719]])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print column 1\nprint(x)\nprint(x[:,1])","execution_count":23,"outputs":[{"output_type":"stream","text":"tensor([[ 0.0724, -1.6412,  0.6088],\n        [ 0.0577,  0.7010, -3.0751],\n        [ 1.1105,  1.9849,  0.9175],\n        [ 0.7105,  0.1287, -1.3437],\n        [-0.1131, -1.0991,  0.8635]])\ntensor([-1.6412,  0.7010,  1.9849,  0.1287, -1.0991])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Resize tensor with torch.view\nx = torch.randn(4,4)\ny = x.view(16) # one row of 16 values from x\ny","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"tensor([-1.0380,  0.8612,  0.3663, -1.1201, -0.9282, -0.1784, -0.5630, -0.9210,\n        -0.5400,  3.0207,  0.4631, -0.0550, -0.5007, -0.8368, -0.2603, -1.8995])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"z = x.view(-1,8) # the size -1 is inferred from other dimensions\nz","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"tensor([[-1.0380,  0.8612,  0.3663, -1.1201, -0.9282, -0.1784, -0.5630, -0.9210],\n        [-0.5400,  3.0207,  0.4631, -0.0550, -0.5007, -0.8368, -0.2603, -1.8995]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x.size(), y.size(), z.size())","execution_count":28,"outputs":[{"output_type":"stream","text":"torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = torch.randn(1)\nprint(x)\nprint(x.item()) # Only works for one element tensor","execution_count":31,"outputs":[{"output_type":"stream","text":"tensor([1.2565])\n1.256506085395813\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Convert from Torch tensor to NumPy array"},{"metadata":{},"cell_type":"markdown","source":"## To NumPy"},{"metadata":{"trusted":true},"cell_type":"code","source":"a = torch.ones(5)\nprint(a)","execution_count":40,"outputs":[{"output_type":"stream","text":"tensor([1., 1., 1., 1., 1.])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert to NumPy with torch.numpy()\nb = a.numpy()\nprint(b)\nprint(type(b))","execution_count":41,"outputs":[{"output_type":"stream","text":"[1. 1. 1. 1. 1.]\n<class 'numpy.ndarray'>\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# NumPy array changes in values \na.add_(1)\nprint(a)\nprint(b)","execution_count":42,"outputs":[{"output_type":"stream","text":"tensor([2., 2., 2., 2., 2.])\n[2. 2. 2. 2. 2.]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## From NumPy"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\na = np.ones(5)\nb = torch.from_numpy(a)\nnp.add(a, 1, out=a)\nprint(a)\nprint(b)","execution_count":43,"outputs":[{"output_type":"stream","text":"[2. 2. 2. 2. 2.]\ntensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# CUDA Tensor"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use GPU/CUDA when available\n# CUDA: Compute Unified Device Architecture, created by Nvidia\n# Uses GPU to perform parallel programming tasks\n\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    y = torch.ones_like(x, device=device) # Creates tensor directly on GPU\n    x = x.to(device)\n    z = x + y\n    print(z)\n    print(z.to(\"cpu\", torch.double))\nelse:\n    print(\"No GPU found!\")","execution_count":44,"outputs":[{"output_type":"stream","text":"No GPU found!\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Output (if run GPU)\ntensor([0.6469], device='cuda:0')\ntensor([0.6469], dtype=torch.float64)"},{"metadata":{},"cell_type":"markdown","source":"# Autograd"},{"metadata":{},"cell_type":"markdown","source":"Allows for automatic differentiation for all operations on a Tensor."},{"metadata":{},"cell_type":"markdown","source":"## Tensor"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set requires_grade=True to track computations\nx = torch.ones(2,2, requires_grad=True)\nprint(x)","execution_count":55,"outputs":[{"output_type":"stream","text":"tensor([[1., 1.],\n        [1., 1.]], requires_grad=True)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = x + 2\nprint(y)","execution_count":56,"outputs":[{"output_type":"stream","text":"tensor([[3., 3.],\n        [3., 3.]], grad_fn=<AddBackward0>)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y was created as a result of operation\n# hence it has grad_fn\nprint(y.grad_fn)","execution_count":57,"outputs":[{"output_type":"stream","text":"<AddBackward0 object at 0x7f1b36b58410>\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"z = y * y * 3\nout = z.mean()\n\nprint(z, out)","execution_count":60,"outputs":[{"output_type":"stream","text":"tensor([[27., 27.],\n        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# .requires_grad_( ... ) changes the requires_grad attribute\na = torch.randn(2,2)\na = ((a * 3) / (a - 1))\nprint(a.requires_grad)\na.requires_grad_(True) # requires _ after requires_grad to make a change\nprint(a.requires_grad)\nb = (a * a).sum()\nprint(b.grad_fn)","execution_count":67,"outputs":[{"output_type":"stream","text":"False\nTrue\n<SumBackward0 object at 0x7f1b35bea490>\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Gradient"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use .backward() to compute derivatives\nprint(out)\nout.backward()","execution_count":71,"outputs":[{"output_type":"stream","text":"tensor(27., grad_fn=<MeanBackward0>)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print d(out)/dx\nprint(x.grad)","execution_count":72,"outputs":[{"output_type":"stream","text":"tensor([[4.5000, 4.5000],\n        [4.5000, 4.5000]])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Example of a vector-Jacobian product\nx = torch.randn(3, requires_grad=True)\n\ny = x * 2\nwhile y.data.norm() < 1000:\n    y = y * 2\n\nprint(y)","execution_count":80,"outputs":[{"output_type":"stream","text":"tensor([  507.2839,  -675.5888, -1428.2904], grad_fn=<MulBackward0>)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"v = torch.tensor([1.0, 0.1, 0.0001], dtype=torch.float)\ny.backward(v)\nprint(x.grad)","execution_count":81,"outputs":[{"output_type":"stream","text":"tensor([2.0480e+03, 2.0480e+02, 2.0480e-01])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Can stop autograd from tracking history on tensors with .requires_grad=True\nprint(x.requires_grad)\nprint((x**2).requires_grad)\n\n# Use torch.no_grad() to stop tracking history\nwith torch.no_grad():\n    print((x**2).requires_grad)","execution_count":82,"outputs":[{"output_type":"stream","text":"True\nTrue\nFalse\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instead use .detach() to get new tensor with same content but does not require gradients\nprint(x.requires_grad)\ny = x.detach()\nprint(y.requires_grad)\nprint(x.eq(y).all())","execution_count":83,"outputs":[{"output_type":"stream","text":"True\nFalse\ntensor(True)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}