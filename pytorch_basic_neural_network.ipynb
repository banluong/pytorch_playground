{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"This notebook will be exploring how PyTorch is used to create a simple neural network. Tutorial for this follows from this link (https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html)"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(nn.Module):\n    # Net using nn.Module to inherit functions\n    def __init__(self):\n        super(Net, self).__init__() # Super for inheritance\n        # 1 input image channel, 6 output channels, 3x3 square conv kernels\n        self.conv1 = nn.Conv2d(1, 6, 3) # nn.Conv2d for conv layer\n        self.conv2 = nn.Conv2d(6, 16, 3)\n        # Apply linear transformation to incoming data y = x*a.T + b\n        self.fc1 = nn.Linear(16 * 6 * 6, 120) # 6x6 from image dimension\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)  # Number of Outputs: 10\n    \n    def forward(self, x):\n        # Max Pooling over a (2,2) window\n        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n        x = F.max_pool2d(F.relu(self.conv2(x)), 2) # If window is square, can just input single value\n        x = x.view(-1, self.num_flat_features(x)) # Transforms to some number of rows and num_flat_features(x) columns\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        \n        return x\n    \n    # Function multiply size of input from one layer to the next\n    def num_flat_features(self, x):\n        size = x.size()[1:] # all dims except batch dimension\n        num_features = 1\n        for s in size:\n            num_features *= s\n        \n        return num_features\n\nnet = Net()\nprint(net)\n            ","execution_count":15,"outputs":[{"output_type":"stream","text":"Net(\n  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n  (fc1): Linear(in_features=576, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=84, bias=True)\n  (fc3): Linear(in_features=84, out_features=10, bias=True)\n)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Learnable parameters of a model are returned by net.parameters()\n\nparams = list(net.parameters())\nprint(len(params))\nprint(params[0].size()) # conv1#s weights","execution_count":16,"outputs":[{"output_type":"stream","text":"10\ntorch.Size([6, 1, 3, 3])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"params[0]","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"Parameter containing:\ntensor([[[[-0.0597, -0.2670,  0.0693],\n          [-0.2468, -0.2974, -0.0986],\n          [-0.2666, -0.0682, -0.2496]]],\n\n\n        [[[-0.3012, -0.3180,  0.0383],\n          [ 0.0104, -0.1344,  0.2940],\n          [ 0.2860,  0.3258, -0.2030]]],\n\n\n        [[[ 0.1441,  0.2834, -0.0368],\n          [-0.0936,  0.0346, -0.2993],\n          [-0.2390,  0.1726,  0.1542]]],\n\n\n        [[[ 0.1103, -0.2230, -0.2753],\n          [-0.1738,  0.2659,  0.0048],\n          [ 0.1810, -0.0565,  0.2537]]],\n\n\n        [[[-0.2153, -0.2751, -0.1657],\n          [ 0.0751,  0.0516,  0.0401],\n          [ 0.2659,  0.1900,  0.2065]]],\n\n\n        [[[ 0.1854,  0.0511,  0.2777],\n          [-0.0159, -0.2373, -0.0024],\n          [-0.1387, -0.1050, -0.1392]]]], requires_grad=True)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Try with random 32x32 input, size of MNIST dataset\ninput = torch.randn(1, 1, 32, 32)\nout = net(input)\nprint(out)","execution_count":20,"outputs":[{"output_type":"stream","text":"tensor([[-0.0425,  0.0506, -0.0261,  0.0432, -0.1079,  0.1634,  0.0515, -0.0571,\n         -0.0591,  0.0404]], grad_fn=<AddmmBackward>)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"input","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"tensor([[[[-0.5225, -1.1788, -0.7394,  ..., -1.9270, -0.8059, -0.3042],\n          [ 0.8579,  0.7384, -1.0661,  ...,  0.1766, -1.3231,  1.5176],\n          [-0.6065, -0.5460,  1.1917,  ...,  0.0115,  0.5774, -0.2858],\n          ...,\n          [ 1.3118, -0.7563, -0.3109,  ..., -0.1542, -0.3895, -0.9130],\n          [ 0.0178,  0.2152,  1.2791,  ...,  0.8881, -0.1599, -1.2267],\n          [ 1.0648, -0.2067,  0.8832,  ..., -0.3742,  0.3771,  0.3171]]]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Zero the gradient buffers of all parameters and backprops with random gradients.\nnet.zero_grad()\nout.backward(torch.randn(1,10))","execution_count":22,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loss Function"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute loss between estimated output and target value\noutput = net(input)\ntarget = torch.randn(10)\ntarget = target.view(1, -1)\ncriterion = nn.MSELoss() # loss function MSE\n\nloss = criterion(output, target) # loss between output computed and target values\nprint(loss)","execution_count":24,"outputs":[{"output_type":"stream","text":"tensor(0.5390, grad_fn=<MseLossBackward>)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calling loss.backwards() computes derivatives w.r.t. the loss\nprint(loss.grad_fn) # MSELoss\nprint(loss.grad_fn.next_functions[0][0]) # Linear\nprint(loss.grad_fn.next_functions[0][0].next_functions[0][0]) # ReLU\n","execution_count":26,"outputs":[{"output_type":"stream","text":"<MseLossBackward object at 0x7fe74e63e0d0>\n<AddmmBackward object at 0x7fe74e63ef10>\n<AccumulateGrad object at 0x7fe74e64b950>\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Back Prop"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Clear existing gradients or else the gradients will be accumulated to existing gradients\nnet.zero_grad() # Zeroes the gradient buffers of all parameters\n\nprint('con1.bias.grad before backward')\nprint(net.conv1.bias.grad)\n\nloss.backward()\n\nprint('conv1.bias.grad after backward')\nprint(net.conv1.bias.grad)","execution_count":27,"outputs":[{"output_type":"stream","text":"con1.bias.grad before backward\ntensor([0., 0., 0., 0., 0., 0.])\nconv1.bias.grad after backward\ntensor([ 0.0006, -0.0110,  0.0099, -0.0038, -0.0004,  0.0050])\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Updating weights"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Implement Gradient Descent with this\nlearning_rate = 0.01\nfor f in net.parameters():\n    f.data.sub_(f.grad.data * learning_rate)","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.optim as optim\n\n# Create optimizer\noptimizer = optim.SGD(net.parameters(), lr=0.01)\n\n# in training loop\noptimizer.zero_grad()\noutput = net(input)\nloss = criterion(output, target)\nloss.backward()\noptimizer.step() # Does update","execution_count":30,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid syntax (<ipython-input-30-41580d3ffb41>, line 4)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-30-41580d3ffb41>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    optimizer = optim.SGD(net.parameters(), lr=0.01))\u001b[0m\n\u001b[0m                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}